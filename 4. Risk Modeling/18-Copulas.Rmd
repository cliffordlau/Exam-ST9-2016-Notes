---
title: "Module 18: Copulas"
author: "C. Lau"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    toc_depth: 4
---

## Module Objective

Desmostrate understanding of the use of copulas as part of the process of modeling multivariate risks, including recommendation of an appropriate copula

***

ERM is interested in all the risk an org faces and ways they interact with each other

Module focus on the theory and application of copulas

Use of the techniques here to model specific types of risk will be covered in part 5

## Recall: Prereq

***PDF and CDF***

For any r.v. $X$:

* PDF: $f(x) = \Pr(X=x)$
* CDF: $F(x) = \Pr(X \leq x)$

Both have a range of $[0,1]$

***Marginal PDF***

$P(X = x) = \sum \limits_y P(X=x, Y=y)$

$f_X(x) = \int \limits_y f_{X,Y}(x,y)dy$

***Conditional PDF***

$P(X=x \mid Y=y) = \dfrac{P(X=x,Y=y)}{P(Y=y)}$

$f_{X \mid Y = y}(x,y) = \dfrac{f_{X,Y}(x,y)}{f_Y(y)}$

***Expectation***

$\mathrm{E}[g(X,Y)] = \sum \limits_x \sum \limits_y g(x,y)P(X=x,Y=y)$

$\int \limits_y \int \limits_x g(x,y)f_{X,Y}(x,y)dxdy$

***Covariance***

$\mathrm{Cov}(X,Y) = \mathrm{E}[(X-\mathrm{E}(X))(Y - \mathrm{E}(Y))] = \mathrm{E}(XY) - \mathrm{E}(X)\mathrm{E}(Y)$

***Correlation***

$\mathrm{Corr}(X,Y) = \rho(X,Y) = \dfrac{\mathrm{Cov}(X,Y)}{\sqrt{\mathrm{Var}(X)\mathrm{Var}(Y)}}$

***Sums and Products of Moments***

$\mathrm{E}(X+Y) = \mathrm{E}(X) + \mathrm{E}(Y)$

$\mathrm{E}(XY) = \mathrm{E}(X)\mathrm{E}(Y) + \mathrm{Cov}(X,Y)$

The above 2 equation are also true for functions $g(X)$ and $h(Y)$ of the r.v.

$\mathrm{Var}(X+Y) = \mathrm{Var}(X) + \mathrm{Var}(Y) + 2\mathrm{Cov}(X, Y)$

## Intro to Copulas

### Joint Distribution Functions

For ERM we need to model all the risks an org. faces and their interdependencies

One way to do so is with a joint distribution function for all the risk

$P(X_i = x_i:i=1...N) = f_{X_1,X_2,...,X_N}(x_1, x_2,...,x_N)$

Corresponding joint (cumulative) distribution functions (CDF):

$P(X_i \leq x_i:i=1...N) = F_{X_1,X_2,...,X_N}(x_1, x_2,...,x_N)$

### Why Copulas Are Useful

Each of the org's risk are represented as the marginal distribution in the context of joint distribution functions

$f_{X_1}(x_1) = \int \limits_{x_2} \dots \int \limits_{x_N} f_{X_1,X_2,...,X_N}(x_1,x_2,...,x_N)dx_2dx_3...dx_N$

The joint distribution will combine information from the marginal risk distribution with other information on the way in which the risks interrelate or depend on one another

The joint distribution expresses this depedence of interrelated factos on one another but it does so **implicity** (You can't immediately see the nature of the interdependence by looking at the formula for the join distribution function)

**Copula** can reflect this interdependence of factors **explicity**

### What is a Copula

Copula ($C$):  
Expresses a multivariate cumulative distribution functions in terms of the individual marginal cumulative distributions

$P(X_i \leq x_i ; i = 1...N) = F_{X_1,...,X_N}(x_1,...,x_N) = C_{X_1,...,X_N}\left[F_{X_1}(x_1),...,F_{X_N}(x_N)\right]$

* Where $C[\dots]$ is the relevant copulat function
* The joint distribution function is epxressed explicitly in terms of the marginal distirubtions and the copula function

**Key Idea**:

$\left\{\left\{\begin{array}{c}\text{Marginal distribution of} \\ \text{each risk factor} \end{array}\right\} \text{combined with {Copula}} \right\} = \left\{\begin{array}{c}\text{Joint distribution of} \\ \text{risk factors} \end{array}\right\}$

Can think of copula as a CDF in many dimensions. It takes marginal probabilities and combines them so as to produce a joint probability

*N*-dimenion copula:

$C(\mathbf{U}) = C(u_1,u_2,...,u_N) = P(U_1 \leq u_1,...,U_N \leq u_N)$

* $u_i = F_{X_i}(x_i)$; i.e. the letter $u$ is used to denote the values of the individual CDFs, each range from $[0,1]$
* $C$ takes in $N$ values in the range $[0,1]$ and returns another value in the range $[0,1]$ since it's a distribution function

***Key beneftis***

* We can deconstruct the joint distribution of a set of variables into components (marginal + copulas)
* We can adjust each component independtly of the others
    * e.g. if the marginal distribution change shape w/o affecting the relative order of the data values within each set of observations
    * And in this case the copula does not change (property of invariance)
    
### Example

Given joint PDF: $f_{X,Y}(x,y) = 6x^2y$ for $0 < x$, $y<1$

Marginal PDF:

* $f_X(x) = \int 6x^2ydy = 3x^2 \int 2ydy = 3x^2$
* $f_Y(y) = \int 6x^2ydx = 2y \int 3x^2 dx = 2y$

Marginal CDF:

* $F_X(x) = x^3$
* $F_Y(y) = y^2$

Joint CDF:

$F_{X,Y}(x,y) = \int \limits_{0}^x \int \limits_{0}^y 6t^2 s ds dt = \int \limits_0^x \left[6t^2 \dfrac{s^2}{2} \right]^y_0 dt = \int \limits_0^x 3t^2y^2 dt = \left[3 \dfrac{t^3}{3} y^2 \right]^x_0 = x^3 y^2$

Copula corresponding to the joint PDF

$u = F_X(x) = x^3 \Rightarrow  x = u^{\frac{1}{3}}$

$u = F_Y(y) = y^2 \Rightarrow  x = v^{\frac{1}{2}}$

$F_{X,Y}(x,y) = x^3y^2 = uv = C_{X,Y}[u,v]$

The joint CDF can be described fully by $C_{X,Y}[u,v]$ and the marginal distributions

## Copulas as Probabilities

Consider how copulas relate to probability distributions and review the concept of dependence

### Basic Properties of Copulas

***Properties of Copulas***

**Property 1**

Increasing the range of values for the variables must increase the probability of observing a combination within that range

$C(u_1,u_2,...,u_N)$ is an increasing function of each input varialbe

* e.g. $C(u_1,u_2,u_3^*,u_4) > C(u_1,u_2,u_3,u_4)$ for $u^*_3 > u_3$
* Extension of the result for a univariate probability distribution function where:  
$F(X^*) = P(X \leq x^*) > P(X \leq x) = F(x)$ if $x^* > x$

**Property 2**

If we "intergrate out" all the other variables (by setting CDFs equal to the maximum value of 1 so as to include all possible values), we will just have the marginal distribution of variable $i$

$C(1,...,1,u_i,1,...,1) = u_i$ for $i=1,2,...,d$ and $u_i \in [0,1]$

**Property 3**

This property ensures that a valid probability (i.e. non-negative) is produced by the copula function for any valid combination of the parameters

For all $(a_1,...,a_N)$ and $(b_1,...,b_N)$ with $0 \leq a_i \leq b_i \leq 1$:  
$\sum \limits_{i_1 = 1}^2 \sum \limits_{i_2 = 1}^2 \dots \sum \limits_{i_N = 1}^2 (-1)^{i_1+\dots+i_N} C(u_{1i_1},...,u_{Ni_N}) \geq 0$

* $u_{j1} = a_j$ and $u_{j2} = b_j$ for $j=1,2,...,N$
* $C$ is the distribution function for the vector of r.v. $(U_1,...,U_N)$

***Example of property 3***

Let $(a_1, a_2)$ and $(b_1, b_2)$ be values such that $0\leq a_1 \leq b_1 \leq 1$ and $0\leq a_2 \leq b_2 \leq 1$

Then:

$\begin{align}
  & \sum \limits_{i_1 = 1}^2 \sum \limits_{i_2 = 1}^2 (-1)^{i_1 + i_2}C(u_{1i_1},u_{2i_2}) \geq 0 \\
  & \Rightarrow \sum \limits_{i_1 = 1}^2 \left((-1)^{i_1 +1}C(u_{1i_1},u_{21}) + (-1)^{i_1 +2} C(u_{1i_1},u_{22}) \right) \geq 0\\
  & \Rightarrow (-1)^2 C(u_{11},u_{21}) + (-1)^3 C(u_{11},u_{22}) + (-1)^3 C(u_{12},u_{21}) + (-1)^4C(u_{12},u_{22}) \geq 0 \\
  & \Rightarrow C(u_{11},u_{21}) - C(u_{11},u_{22}) - C(u_{12},u_{21}) + C(u_{12},u_{22}) \geq 0 \\
\end{align}$

By definition, $u_{11} = a_1$, $u_{21} = a_2$, $u_{12} = b_1$ and $u_{22} = b_2$ so this requires that:

$C(a_1,a_2) - C(a_1,b_2) - C(b_1,a_2) + C(b_1,b_2) \geq 0$

The inequality is equivalent to saying that the rectangle shaded diagonally downwards in the following diagram always has positive probability

![](figures/figure-18.01.png)

Now:  
$\begin{align}
        C(b_1, b_2) - C(a_1, b_2) &= P(U_1 \leq b_1, U_2 \leq b_2) - P(U_1 \leq a_1, U_2 \leq b_2) \\
        &= P(a_1 \leq U_1 \leq b_1, U_2 \leq b_2)\\
      \end{align}$
      
And:  
$\begin{align}
        C(b_1, a_2) - C(a_1, a_2) &= P(U_1 \leq b_1, U_2 \leq a_2) - P(U_1 \leq a_1, U_2 \leq a_2) \\
        &= P(a_1 \leq U_1 \leq b_1, U_2 \leq a_2)\\
      \end{align}$

Substituting into the inequality:

$\begin{align}
  & P(a_1 \leq U_1 \leq b_1, U_2 \leq b_2) - P(a_1 \leq U_1 \leq b_1, U_2 \leq a_2) \geq 0 \\
  & \Rightarrow P(a_1 \leq U_1 \leq b_1, a_2 \leq U_2 \leq b_2) \geq 0
  \end{align}$

### Sklar's Theorem

Let $F$ be a joint distribution function with marginal CDF $F_1,...,F_N$

$\exists \: C : \forall \: x_1,...,x_N \in [-\infty, \infty]$

$F(x_1,...,x_N) = C(F_1(x_1),...,F_N(x_N))$

Sklar's theorm sates that if the marginal cumulative distributions are continuous, then $C$ is unique

Conversely, if $C$ is a copula and $F_1,...,F_N$ are univariate CDF, then the function $F$ ($F(x_1,...,x_N) = C(F_1(x_1),...,F_N(x_N))$) is a joint cumulative distribution function with marginal CDF $F_1,...,F_N$

**Definition of the copula of a distribution**

If the vector of r.v. $X$ has joint CDF $F$ with continuous marginal CDF $F_1,...,F_N$, then the copula of the distribution $F$ is the distribution function $C(F_1(x_1),...,F_N(x_N))$

### Discrete Copulas

Empirical copula function describes the relationship between the marginal variables based upon their respective ranks

* Such functions are examples of discrete (non-continuous) copula functions

Consider a series of joint observations $(X_t, Y_t)$ for $t= 1,2,...,T$

***Method 1***

Define:

$\begin{align} F(x,y) &= \Pr(X_t \leq x, Y_t \leq y)\\
  &= \dfrac{1}{1+T}\sum\limits_{s=1}^T I(X_s \leq x, Y_s \leq y) \\
  \end{align}$
  
* $I(X_s \leq x, Y_s \leq y) = \begin{cases} 1 & \text{if }X_s \leq x \text{ and } Y_s \leq y \\
0 & \text{otherwise} \\ \end{cases}$

In which case:  
$\dfrac{1}{1+T} \leq F(x,y) \leq dfrac{T}{1+T}$

For sample with 99 values this would correspond to $0.01 \leq F(x,y) \leq 0.99$

**Example**

10 vectors of data $\mathbf{X}_1,...,\mathbf{X}_{10}$

* Each contains 2 elements
* For 3 of the 10 observations the first element takes values $\leq 2.7$ and the second takes value $\leq 1.4$

$\hat{F}(2.7,1,4) = \dfrac{1}{11} \times 3 = \dfrac{3}{11} = 0.273$

***Method 2***

Apply a continuity corretion and define:

$\begin{align}
  F(x,y) &= \Pr(X_t \leq x, Y_t \leq y) \\
  &= \dfrac{1}{T} \left[ \sum\limits_{s=1}^T I(X_s \leq x, Y_s \leq y) - \dfrac{1}{2}  \right]
  \end{align}$

In which case:  
$\dfrac{1}{2T} \leq F(x,y) \leq \dfrac{T - \frac{1}{2}}{T}$

**Example**

$\hat{F}(2.7,1,4) = \dfrac{1}{10}(3-0.5) = 0.25$

### Survival Copula

For 2 variables $X$ and $Y$, **key property** of a copula:

$F(x,y) = P[X\leq x, Y\leq y] = C[F_X(x), F_Y(y)]$

For each copula there is a corresponding **survival copula** defined by the "opposite relationship"

$\bar{F}(x,y) = P[X > x, Y > y] = \bar{C}[\bar{F}_X(x), \bar{F}_Y(y)]$

* $\bar{F}_X(x) = 1 - F_X(x)$
* $\bar{F}_Y(y) = 1 - F_Y(y)$

So the survival copula expresses the joint survival probability in terms of the marginal survival probabilities

